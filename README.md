# Computer Architecture
This repository contains some of my lab files from my university computer architecture course during my Junior Fall semester.

## Lab 1:  Iterative Integer Multiplier
The purpose of this lab is to design two implementations of an integer iterative multiplier – a baseline design and an alternative design. The baseline design is a fixed-latency implementation that always takes the same number of cycles. The baseline design implements a design pattern of a control unit and datapath split. The control unit iterates through 35 cycles, with 1 cycle for the IDLE state, 32 cycles for iterative calculation, 1 cycle to realize that the calculations are done, and 1 for the DONE state. At the CALC state, the baseline design iterates through all 32 bits of the operand, applying a series of add and shift operations. The alternative design is a variable-latency implementation that depends on the properties of the input operands to reduce execution time. In the CALC state, instead of iterating through all the bits of the 32-bit operand, shifting by 1 bit for every cycle, the alternative design counts the number of consecutive least significant bit zeros, shift through those zeros, to reach the next 1, which signifies a new cycle that utilizes the addition operator. 

In lecture, the professor used the analogy of multiple people doing laundry to explain resource utilization and pipelining. This lab connects to the lecture material because students can think of the baseline multiplier as the fixed time slot laundry (single cycle processor), and the alternative design as the variable time slot laundry (FSM Processors). In the lecture material, for the fixed time slot laundry, from 10 pm to 11pm, even though it was Ben’s time slot, no actions (calculations) were taken because Ben doesn’t fold his clothes or put them in his closet. The baseline design is the same, no action (the add operator) was taken when the least significant bit is a zero, and the control unit simply goes to the next bit/cycle, by shifting by one. This lab allows students to explore how we can make better use of competitive resources. The fixed latency multiplier design processed every bit, but the alternative multiplier design “skips” over unnecessary steps by jumping over zeros. The next lab requires students to implement a pipeline processor, which corresponds to the pipeline laundry discussed in class, further speeds up the execution time. This lab also encourages students to compare the varying levels of modeling: the given FL model, and the fixed-latency RTL model, and the variable-latency RTL model.

## Lab 2: Pipelined Processor
The purpose of this lab was to design two pipelined processor microarchitectures for the TinyRV2 instruction set architecture: a baseline design that avoids hazards by stalling and an alternative design that uses bypassing. The baseline design employs stall and squash mechanisms to resolve various hazards, while the alternative design uses bypassing to forward values from the Execute (X), Memory (M), and Writeback (W) stages to the Decode (D) stage, enhancing performance. This lab reinforced lecture concepts, helping students understand instruction set architecture, pipelined processor microarchitecture, hazard handling techniques, message interfaces, and performance evaluation. Frequent reference to the RISC-V ISA manual while implementing TinyRV2 instructions improved familiarity with assembly syntax, semantics, and instruction encoding. In lectures, we explored different processor designs and evaluated their performance. A single-cycle processor has a CPI of 1 but a longer cycle time. An FSM processor has a CPI greater than 1 with a shorter cycle time. The pipelined processor enables overlapping execution of multiple transactions, and despite introducing hazards that complicate control, it still achieves an average of one cycle per instruction (CPI) with a shorter cycle time once the pipeline is fully loaded. 

This lab allows students to test and verify the performance characteristics discussed in lectures through their own code implementation. In lectures, the professor guided us in drawing datapath diagrams and control units for all three processor types using the TinyRV1 subset of the RISC-V ISA. For this lab, students practiced creating their own datapath diagrams for each instruction, using an incremental development design methodology similar to the professor’s approach—starting with ADD, followed by ADDI, MUL, and other instructions until the entire TinyRV1 ISA was supported. Students also get to practice perhaps the most complicated part of the lab, logic explicit to pipeline processor microarchitecture that involves complicated pipelined control logic and control unit table, stall and squash logic, and bypassing logic in the control unit. For this lab, students implemented a pipelined processor, further increasing the speed of the multiplier instruction compared to the variable latency alternative design which improved upon the fixed latency baseline design, in lab 1. This lab also utilizes solutions from the first lab, with the variable latency multiplier being a vital component in the datapath. This lab gives students more practice with abstraction levels such as the functional (already implemented by course staff) and the register-transfer-level modeling. Like in lab 1, students continue to practice the control/datapath split, but this time instead of having a FSM control, a pipelined control is used with this more complicated microarchitecture design.

## Lab 3: Blocking Cache
The purpose of this lab was to create two finite-state-machine (FSM) cache microarchitectures. The baseline design is a direct-mapped, write-back, write-allocate cache, while the second is a two-way set associative cache that avoids conflict misses and lowers miss rates. This lab enables students to apply concepts from lectures, including memory system design, complex FSM cache controllers, cache associativity techniques, abstraction levels, design principles, design patterns, and agile methodologies. Similar to Lab 1, we implemented an FSM control pattern, but this unit is more complex, managing various latency-insensitive interfaces, initialization transactions, and eviction responses. 

This FSM cache architecture features a hit latency of four cycles (I → TC → RD → W), in contrast to Lab 1’s single-cycle memory access time. We also employed the control/datapath split design pattern and extensively applied latency-insensitive stream interfaces using the val/rdy micro-protocol. In the baseline design, we established a direct-mapped cache with cache lines restricted to specific locations. The alternative design, a two-way set associative cache, allows cache lines to occupy one of two locations. Both designs utilize a write-back, write-allocate policy to handle write misses, only committing writes to memory when cache lines are evicted. Additionally, these caches can serve as components in a larger multi-bank cache system. This lab provided valuable experience in optimizing cache microarchitecture designs to reduce miss rates.

## Lab 4:  Single-Core and Multi-Core Systems
The purpose of this lab is to build a single-core system with its own instruction and data cache, and a multi-core system with four caches, each having a private instruction cache and a shared banked data cache. The multi-core system exploits thread-level parallelism by allocating different threads within a single program to the different cores on a chip, aiming for an ideal P× speedup. This lab allows students to gain hands-on practice with lecture material, deepening their understanding of composing simpler subsystems to create more complex systems, programming single and multi-threaded C programs, and understanding the interaction between hardware and software design. 

This lab relates to the previous labs because it integrates the multiplier, processor, and cache from the first three labs with the network to implement a multicore system featuring private instruction caches and a shared, banked data cache. It utilizes our solutions from the initial three labs. The single-core system hardware comprises the processor from Lab 2 (which includes the multiplier from Lab 1) and two instances of the cache from Lab 3 (one serving as the instruction cache and the other as the data cache). In contrast, the multi-core system hardware includes four instances of the processor from Lab 2 (each incorporating the multiplier from Lab 1) and eight instances of the cache from Lab 3 (four instruction caches and four data caches). A ring network interconnects the processors to the data caches and links the caches to the main memory interfaces. 

Both designs consist of hardware and software components. The baseline design combines single-core system hardware and single-core system software in the form of a single-threaded sorting microbenchmark. The single-threaded sorting algorithm, implemented in C, sorts an array of integers using a quick sort. For this lab, a quick sort was implemented as the software component of the single-core system. The alternative design merges multi-core system hardware and multi-core system software in the form of a multi-threaded sorting
